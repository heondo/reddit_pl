{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# practice huuuuub so i dont have to create an API call every five minutes LMFAO\n",
    "import lambda_function as lmbda\n",
    "import personal_funcs as mf\n",
    "import boto3\n",
    "import praw\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from dateutil import parser\n",
    "import pprint\n",
    "from ast import literal_eval\n",
    "import re\n",
    "from decimal import Decimal\n",
    "from functools import reduce\n",
    "import os\n",
    "import amazondax\n",
    "import botocore.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /home/heondokim/envs/reddit_pl/bin/python3\n",
    "import boto3\n",
    "import praw\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from dateutil import parser\n",
    "import pprint\n",
    "from ast import literal_eval\n",
    "import re\n",
    "from decimal import Decimal\n",
    "from functools import reduce\n",
    "import os\n",
    "import amazondax\n",
    "import botocore.session\n",
    "\n",
    "\n",
    "def subs_to_json(top_posts, curr_time, subredd):\n",
    "    subs_json = []\n",
    "    for sub in top_posts:\n",
    "        sub.comments.replace_more(limit=None)\n",
    "        temp = {\"author\" : sub.author.name,\n",
    "        \"comments\" : sub.comments,\n",
    "        \"date_uploaded\": curr_time,\n",
    "        \"created_utc\" : sub.created_utc,\n",
    "        \"distinguished\" : sub.distinguished,\n",
    "        \"edited\" : sub.edited,\n",
    "        \"id\" : sub.id,\n",
    "        \"is_self\" : sub.is_self,\n",
    "        # \"link_flair_template_id\" : sub.link_flair_template_id,\n",
    "        \"link_flair_text\" : sub.link_flair_text,\n",
    "        \"locked\" : sub.locked,\n",
    "        \"name\" : sub.name,\n",
    "        \"num_comments\" : sub.num_comments,\n",
    "        \"over_18\" : sub.over_18,\n",
    "        \"permalink\" : sub.permalink,\n",
    "        \"score\" : sub.score,\n",
    "        \"selftext\" : sub.selftext,\n",
    "        \"spoiler\" : sub.spoiler,\n",
    "        \"stickied\" : sub.stickied,\n",
    "        \"subreddit\" : subredd,\n",
    "        \"title\" : sub.title,\n",
    "        \"upvote_ratio\" : sub.upvote_ratio,\n",
    "        \"url\" : sub.url\n",
    "        }\n",
    "        subs_json.append(temp)\n",
    "    return subs_json\n",
    "\n",
    "def commtree_json(comment_tree, curr_time, subredd):\n",
    "    comm_tree_list = []\n",
    "    for sub in comment_tree.list():\n",
    "        try:\n",
    "            temp = {\"author\" : sub.author.name,\n",
    "            \"body\": sub.body,\n",
    "            # \"comments\" : sub.comments,\n",
    "            \"date_uploaded\": curr_time,\n",
    "            \"created_utc\" : sub.created_utc,\n",
    "            \"distinguished\" : sub.distinguished,\n",
    "            \"edited\" : sub.edited,\n",
    "            \"id\" : sub.id,\n",
    "            \"is_submitter\" : sub.is_submitter,\n",
    "            \"link_id\" : sub.link_id,\n",
    "            \"parent_id\" : sub.parent_id,\n",
    "            # \"locked\" : sub.locked,\n",
    "            # \"name\" : sub.name,\n",
    "            # \"num_comments\" : sub.num_comments,\n",
    "            # \"over_18\" : sub.over_18,\n",
    "            \"permalink\" : sub.permalink,\n",
    "            \"score\" : sub.score,\n",
    "            # \"selftext\" : sub.selftext,\n",
    "            # \"spoiler\" : sub.spoiler,\n",
    "            \"stickied\" : sub.stickied,\n",
    "            \"subreddit_id\" : sub.subreddit_id,\n",
    "            \"subreddit\" : \"weedstocks\"\n",
    "            # \"title\" : sub.title,\n",
    "            # \"upvote_ratio\" : sub.upvote_ratio,\n",
    "            # \"url\" : sub.url\n",
    "            }\n",
    "            # print(temp)\n",
    "            comm_tree_list.append(temp)\n",
    "        except:\n",
    "            temp = {\"author\" : None,\n",
    "            \"body\": sub.body,\n",
    "            # \"comments\" : sub.comments,\n",
    "            \"date_uploaded\": curr_time,\n",
    "            \"created_utc\" : sub.created_utc,\n",
    "            \"distinguished\" : sub.distinguished,\n",
    "            \"edited\" : sub.edited,\n",
    "            \"id\" : sub.id,\n",
    "            \"is_submitter\" : sub.is_submitter,\n",
    "            \"link_id\" : sub.link_id,\n",
    "            \"parent_id\" : sub.parent_id,\n",
    "            # \"locked\" : sub.locked,\n",
    "            # \"name\" : sub.name,\n",
    "            # \"num_comments\" : sub.num_comments,\n",
    "            # \"over_18\" : sub.over_18,\n",
    "            \"permalink\" : sub.permalink,\n",
    "            \"score\" : sub.score,\n",
    "            # \"selftext\" : sub.selftext,\n",
    "            # \"spoiler\" : sub.spoiler,\n",
    "            \"stickied\" : sub.stickied,\n",
    "            \"subreddit_id\" : sub.subreddit_id,\n",
    "            \"subreddit\" : \"weedstocks\"\n",
    "            # \"title\" : sub.title,\n",
    "            # \"upvote_ratio\" : sub.upvote_ratio,\n",
    "            # \"url\" : sub.url\n",
    "            }\n",
    "            comm_tree_list.append(temp)\n",
    "            print(sub.id, \"comment deleted\")\n",
    "    return comm_tree_list\n",
    "\n",
    "\n",
    "\n",
    "def subs_to_comms(jsonofsubs, curr_time, subredd):\n",
    "    comm_json = []\n",
    "    for values in jsonofsubs:\n",
    "        # print(values.items())\n",
    "        # print(values[\"comments\"])\n",
    "        temp = commtree_json(values[\"comments\"], curr_time, subredd)\n",
    "        comm_json.append(temp)\n",
    "    comm_json1 = [x for x in comm_json if x != []]\n",
    "    return comm_json1\n",
    "\n",
    "def remove_comments(subsofjson):\n",
    "    # what = literal_eval(subs_to_json)\n",
    "    subsofjson.pop(\"comments\")\n",
    "    return subsofjson\n",
    "\n",
    "\n",
    "# build class for praw object...I think\n",
    "def txt_json(text):\n",
    "    thing = open(text, 'r').read()\n",
    "    thing = json.loads(thing, parse_float=Decimal)\n",
    "    return thing\n",
    "\n",
    "# i just need...to write a function that will take in the list of submissions\n",
    "# and create the list of comments. So basically, map comment_tree to sub_json\n",
    "# what i was doing before is fine i just need to remember to pop the comment forest....\n",
    "# i believe. but yeah back....again\n",
    "def upload_to_s3(data, types, time_stamp):\n",
    "    with open(\"/tmp/{}_data.txt\".format(types), \"w\") as outfile:\n",
    "        json.dump(data, outfile)\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket('cannabis-stocks')\n",
    "    bucket.upload_file(\"/tmp/{}_data.txt\".format(types),\"{}/{}.txt\".format(types, time_stamp))\n",
    "\n",
    "\n",
    "# functions to take list of json posts, list of list of comments\n",
    "# convert to dataframes and do cleaning...I think\n",
    "# def type_conf(list_of_stuff):\n",
    "#     try:\n",
    "#         if isinstance(list_of_stuff[0], list):\n",
    "#             return \"comments\"\n",
    "#         else:\n",
    "#             return \"submissions\"\n",
    "#     except:\n",
    "#         print(\"neither sub or comment\")\n",
    "\n",
    "\n",
    "def comm_to_df(lists):\n",
    "    temp = list(map(pd.DataFrame.from_records, lists))\n",
    "    temp = reduce(lambda x, y: pd.concat([x, y]), temp)\n",
    "    return temp\n",
    "\n",
    "\n",
    "def create_df(text_file, typer):\n",
    "    lists = txt_json('/tmp/{}.txt'.format(text_file))\n",
    "    if typer == 'comments':\n",
    "        thing = comm_to_df(lists)\n",
    "    elif typer == 'submits':\n",
    "        thing = pd.DataFrame.from_records(lists)\n",
    "        thing['selftext'] = np.where(thing['selftext'] == \"\", None, thing['selftext'])\n",
    "    return thing\n",
    "\n",
    "def fix_subs(subDF):\n",
    "    subDF['distinguished'] = subDF['distinguished'].fillna(\"false\")\n",
    "    subDF['selftext'] = subDF['selftext'].fillna(\"false\")\n",
    "    # turn it into a json, reread with parse decimal?\n",
    "    return subDF\n",
    "\n",
    "def fix_comms(commDF):\n",
    "    commDF['author'] = commDF['author'].fillna(\"false\")\n",
    "    commDF['distinguished'] = commDF['distinguished'].fillna(\"false\")\n",
    "    return commDF\n",
    "\n",
    "def df_json_dynamo(data, dynadb):\n",
    "    resource = boto3.resource('dynamodb', region_name='us-west-2')\n",
    "    table = resource.Table(dynadb)\n",
    "    item = data.T.to_dict().values()\n",
    "    for i in item:\n",
    "        # try:\n",
    "        table.put_item(Item=i)\n",
    "        # except:\n",
    "        #     # so automoderator posts dont work, i think its because the files are different\n",
    "        #     print('failed with {}'.format(i['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_creds = mf.txt_json('config/reddit_creds.txt')\n",
    "event = {\n",
    "        \"id\": \"cdc73f9d-aea9-11e3-9d5a-835b769c0d9c\",\n",
    "        \"detail-type\": \"Scheduled Event\",\n",
    "        \"source\": \"aws.events\",\n",
    "        \"account\": \"{{account-id}}\",\n",
    "        \"time\": \"2019-06-11T00:00:00Z\",\n",
    "        \"region\": \"us-west-2\",\n",
    "        \"resources\": [\n",
    "            \"arn:aws:events:us-west-2:123456789012:rule/ExampleRule\"\n",
    "        ],\n",
    "        \"detail\": {}\n",
    "        }\n",
    "context = None\n",
    "time_rn = parser.parse(event['time'])\n",
    "time_rn = re.sub(r' ', '_', str(time_rn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etn2wud comment deleted\n",
      "etm35ot comment deleted\n",
      "etlg5w3 comment deleted\n",
      "etlv16k comment deleted\n",
      "etm5qi0 comment deleted\n",
      "etl5inu comment deleted\n",
      "etm845j comment deleted\n",
      "etlsai3 comment deleted\n",
      "etm6hv9 comment deleted\n",
      "etm6tun comment deleted\n",
      "etm9ejk comment deleted\n",
      "etmh2fn comment deleted\n",
      "etlnowp comment deleted\n",
      "etlvei9 comment deleted\n",
      "etle91f comment deleted\n",
      "etlte5u comment deleted\n",
      "etmddse comment deleted\n",
      "etlmedh comment deleted\n",
      "etm8add comment deleted\n",
      "etm8ial comment deleted\n",
      "etm5ph9 comment deleted\n",
      "etmbdve comment deleted\n",
      "etlf6nh comment deleted\n",
      "etmawhu comment deleted\n",
      "etm9ol8 comment deleted\n",
      "etmaysc comment deleted\n",
      "etm7pww comment deleted\n",
      "etm7v2o comment deleted\n",
      "etm7kto comment deleted\n",
      "etlnxd0 comment deleted\n",
      "etlntb6 comment deleted\n",
      "etloapz comment deleted\n",
      "etlo1ip comment deleted\n",
      "etlnwgz comment deleted\n",
      "etlo01a comment deleted\n",
      "etleqrh comment deleted\n",
      "etm686d comment deleted\n",
      "etm2sld comment deleted\n",
      "etm5vxq comment deleted\n",
      "etlfhkm comment deleted\n",
      "etm2vo6 comment deleted\n",
      "etmht4p comment deleted\n",
      "etlo185 comment deleted\n",
      "etlpu0z comment deleted\n",
      "etlohhv comment deleted\n",
      "etlfcx1 comment deleted\n",
      "etleusb comment deleted\n",
      "etlpwd0 comment deleted\n",
      "etlol5h comment deleted\n",
      "etmtc1k comment deleted\n",
      "etmn27t comment deleted\n",
      "etmn8pe comment deleted\n",
      "etmngvk comment deleted\n"
     ]
    }
   ],
   "source": [
    "r_object =  lmbda.reddit_posts(configs=reddit_creds, subredd='weedstocks', time_period= 'day', \n",
    "                                      limit_num = 5, curr_time=time_rn)\n",
    "r_object.pop_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that I know my reddit class works to....get the top posts and submissions.\n",
    "# I can easily create a class function to send to s3 based on the type of data\n",
    "# another function for the class is to insert update into dynamoDB, with all of my stuff being cleaned prior.\n",
    "def fix_subs(subDF):\n",
    "    subDF['distinguished'] = subDF['distinguished'].fillna(\"false\")\n",
    "    subDF['selftext'] = subDF['selftext'].fillna(\"false\")\n",
    "#     sub_j = subDF.to_json(orient='columns')\n",
    "#     subDF = json.loads(sub_j, parse_float=Decimal)\n",
    "    return subDF\n",
    "\n",
    "def fix_comms(commDF):\n",
    "    commDF['author'] = commDF['author'].fillna(\"false\")\n",
    "    commDF['distinguished'] = commDF['distinguished'].fillna(\"false\")\n",
    "#     comm_j = commDF.to_json(orient='columns')\n",
    "#     commDF = json.loads(comm_j, parse_float=Decimal)\n",
    "    return commDF\n",
    "\n",
    "def create_df(text_file):\n",
    "    lists = txt_json('/tmp/{}_data.txt'.format(text_file))\n",
    "    if text_file == 'comments':\n",
    "        thing = comm_to_df(lists)\n",
    "    elif text_file == 'submits':\n",
    "        thing = pd.DataFrame.from_records(lists)\n",
    "        thing['selftext'] = np.where(thing['selftext'] == \"\", None, thing['selftext'])\n",
    "    return thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "subDF = create_df(\"submits\")\n",
    "commDF = create_df(\"comments\")\n",
    "subDF = fix_subs(subDF)\n",
    "commDF = fix_comms(commDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['author', 'body', 'created_utc', 'date_uploaded', 'distinguished', 'edited', 'id', 'is_submitter', 'link_id', 'parent_id', 'permalink', 'score', 'stickied', 'subreddit', 'subreddit_id']\n"
     ]
    }
   ],
   "source": [
    "subDF.head()\n",
    "print(sorted(commDF.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>date_uploaded</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>edited</th>\n",
       "      <th>id</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>score</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gailjnh</td>\n",
       "      <td>From the article: \"the state legislature has m...</td>\n",
       "      <td>1562928376.0</td>\n",
       "      <td>2019-07-12_17:49:53.711280</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>etl9jvx</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_cc99jk</td>\n",
       "      <td>t3_cc99jk</td>\n",
       "      <td>/r/weedstocks/comments/cc99jk/illinois_just_le...</td>\n",
       "      <td>88</td>\n",
       "      <td>False</td>\n",
       "      <td>weedstocks</td>\n",
       "      <td>t5_2zfqj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>schrikk</td>\n",
       "      <td>I'm all for canabis legalization but no way wo...</td>\n",
       "      <td>1562930646.0</td>\n",
       "      <td>2019-07-12_17:49:53.711280</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>etlbeot</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_cc99jk</td>\n",
       "      <td>t3_cc99jk</td>\n",
       "      <td>/r/weedstocks/comments/cc99jk/illinois_just_le...</td>\n",
       "      <td>47</td>\n",
       "      <td>False</td>\n",
       "      <td>weedstocks</td>\n",
       "      <td>t5_2zfqj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MaximumRecursion</td>\n",
       "      <td>I know our media and politicians are utter cra...</td>\n",
       "      <td>1562933041.0</td>\n",
       "      <td>2019-07-12_17:49:53.711280</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>etldmg4</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_cc99jk</td>\n",
       "      <td>t3_cc99jk</td>\n",
       "      <td>/r/weedstocks/comments/cc99jk/illinois_just_le...</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>weedstocks</td>\n",
       "      <td>t5_2zfqj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CannaVestments</td>\n",
       "      <td>\"Cassidy stated that the new law as passed wil...</td>\n",
       "      <td>1562936733.0</td>\n",
       "      <td>2019-07-12_17:49:53.711280</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>etlhpk9</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_cc99jk</td>\n",
       "      <td>t3_cc99jk</td>\n",
       "      <td>/r/weedstocks/comments/cc99jk/illinois_just_le...</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>weedstocks</td>\n",
       "      <td>t5_2zfqj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PissedOffPedro</td>\n",
       "      <td>They gotta do something to fix that crippling ...</td>\n",
       "      <td>1562935617.0</td>\n",
       "      <td>2019-07-12_17:49:53.711280</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>etlgdy7</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_cc99jk</td>\n",
       "      <td>t3_cc99jk</td>\n",
       "      <td>/r/weedstocks/comments/cc99jk/illinois_just_le...</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>weedstocks</td>\n",
       "      <td>t5_2zfqj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                               body  \\\n",
       "0           Gailjnh  From the article: \"the state legislature has m...   \n",
       "1           schrikk  I'm all for canabis legalization but no way wo...   \n",
       "2  MaximumRecursion  I know our media and politicians are utter cra...   \n",
       "3    CannaVestments  \"Cassidy stated that the new law as passed wil...   \n",
       "4    PissedOffPedro  They gotta do something to fix that crippling ...   \n",
       "\n",
       "    created_utc               date_uploaded distinguished edited       id  \\\n",
       "0  1562928376.0  2019-07-12_17:49:53.711280         false  False  etl9jvx   \n",
       "1  1562930646.0  2019-07-12_17:49:53.711280         false  False  etlbeot   \n",
       "2  1562933041.0  2019-07-12_17:49:53.711280         false  False  etldmg4   \n",
       "3  1562936733.0  2019-07-12_17:49:53.711280         false  False  etlhpk9   \n",
       "4  1562935617.0  2019-07-12_17:49:53.711280         false  False  etlgdy7   \n",
       "\n",
       "   is_submitter    link_id  parent_id  \\\n",
       "0          True  t3_cc99jk  t3_cc99jk   \n",
       "1         False  t3_cc99jk  t3_cc99jk   \n",
       "2         False  t3_cc99jk  t3_cc99jk   \n",
       "3         False  t3_cc99jk  t3_cc99jk   \n",
       "4         False  t3_cc99jk  t3_cc99jk   \n",
       "\n",
       "                                           permalink  score  stickied  \\\n",
       "0  /r/weedstocks/comments/cc99jk/illinois_just_le...     88     False   \n",
       "1  /r/weedstocks/comments/cc99jk/illinois_just_le...     47     False   \n",
       "2  /r/weedstocks/comments/cc99jk/illinois_just_le...     33     False   \n",
       "3  /r/weedstocks/comments/cc99jk/illinois_just_le...     12     False   \n",
       "4  /r/weedstocks/comments/cc99jk/illinois_just_le...      6     False   \n",
       "\n",
       "    subreddit subreddit_id  \n",
       "0  weedstocks     t5_2zfqj  \n",
       "1  weedstocks     t5_2zfqj  \n",
       "2  weedstocks     t5_2zfqj  \n",
       "3  weedstocks     t5_2zfqj  \n",
       "4  weedstocks     t5_2zfqj  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commDF.head()\n",
    "# this should be enough for a \"cleaned\" df that will at least go into dynamodb cleanly....\n",
    "# anything else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_json_dynamo(data, dynadb):\n",
    "    resource = boto3.resource('dynamodb', region_name='us-west-2')\n",
    "    table = resource.Table(dynadb)\n",
    "    item = data.T.to_dict().values()\n",
    "    for i in item:\n",
    "        table.put_item(Item=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heondokim/envs/reddit_pl/lib/python3.5/site-packages/ipykernel_launcher.py:4: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_json_dynamo(subDF, \"submits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
